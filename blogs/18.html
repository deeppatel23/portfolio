<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Introduction to Natural Language Processing</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Introduction to Natural Language Processing</h1>
</header>
<section data-field="subtitle" class="p-summary">
NLP is a great tool to analyze text data and perform an amazing task when combined with machine learning and deep learning. So, let’s look…
</section>
<section data-field="body" class="e-content">
<section name="f1ef" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--fullWidth"><figure name="a13a" id="a13a" class="graf graf--figure graf--layoutFillWidth graf--leading"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 150%;"></div><img class="graf-image" data-image-id="0*k20llWDKwUSRBUDd" data-width="4000" data-height="6000" data-unsplash-photo-id="ncLdDcvrcfw" data-is-featured="true" src="https://cdn-images-1.medium.com/max/2560/0*k20llWDKwUSRBUDd"></div><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-creator noopener noopener" target="_blank">Jason Leung</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-source noopener noopener" target="_blank">Unsplash</a></figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><h4 name="3f85" id="3f85" class="graf graf--h4 graf-after--figure graf--kicker"><a href="https://towardsai.net/p/category/nlp" data-href="https://towardsai.net/p/category/nlp" class="markup--anchor markup--h4-anchor">Natural Language Processing</a></h4><h3 name="e5d5" id="e5d5" class="graf graf--h3 graf-after--h4 graf--title">Introduction to Natural Language Processing</h3><h4 name="bbf2" id="bbf2" class="graf graf--h4 graf-after--h3 graf--subtitle">NLP is a great tool to analyze text data and perform an amazing task when combined with machine learning and deep learning. So, let’s look into the big picture of NLP.</h4><p name="461c" id="461c" class="graf graf--p graf-after--h4">Advancement in technology has given a new direction to our way of life. Starting from generating tonnes of data, to extracting a deep insight from it, and thus making most of the businesses data-driven. Most of the data that is generated is in the form of text or human language, that it hard for the machine to understand. This text data is generated when we speak, send WhatsApp Message, send an E-Mail, health care data, social media posts, tweets, and even when we a review of a product. These data cannot be directly fed to our model as it contains lots of noise. It needs to be thoroughly processed before use.</p><p name="a81c" id="a81c" class="graf graf--p graf-after--p">Thus, to solve this problem there’s come into the picture “<strong class="markup--strong markup--p-strong">Natural Language Processing</strong>”, frequently known as NLP. Natural Language Processing is a key segment of AI focussed to understand and analyze hidden patterns in text form of data. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as — automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation, etc.</p><h3 name="eb3b" id="eb3b" class="graf graf--h3 graf-after--p">Text Preprocessing</h3><figure name="d73a" id="d73a" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 467px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><img class="graf-image" data-image-id="0*csZ_-Vo4b23zLOXL" data-width="5184" data-height="3456" data-unsplash-photo-id="gnyA8vd3Otc" src="https://cdn-images-1.medium.com/max/800/0*csZ_-Vo4b23zLOXL"></div><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@hishahadat?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com/@hishahadat?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-creator noopener" target="_blank">Shahadat Rahman</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-source noopener" target="_blank">Unsplash</a></figcaption></figure><p name="000f" id="000f" class="graf graf--p graf-after--figure">Text data is one of the most unstructured forms of available data. To make this data noise-free, we have various methods in NLP.</p><h4 name="4821" id="4821" class="graf graf--h4 graf-after--p">Noise Reduction</h4><p name="fe98" id="fe98" class="graf graf--p graf-after--h4">Noise such as punctuation marks is of no meaning when it comes to a machine. These need to be removed from the data.</p><pre name="69c9" id="69c9" class="graf graf--pre graf-after--p">import re</pre><pre name="e52b" id="e52b" class="graf graf--pre graf-after--pre">text = &quot;What is NLP? Why, do we need to reduce noise?&quot;</pre><pre name="4974" id="4974" class="graf graf--pre graf-after--pre"># remove punctuation<br>result = re.sub(r&#39;[\.\?\!\,\:\;\&quot;]&#39;, &#39;&#39;, text)</pre><pre name="7c2a" id="7c2a" class="graf graf--pre graf-after--pre">print(result)</pre><pre name="952c" id="952c" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">#What is NLP Why do we need to reduce noise</em></pre><h4 name="0a5c" id="0a5c" class="graf graf--h4 graf-after--pre">Tokenization</h4><p name="2d5f" id="2d5f" class="graf graf--p graf-after--h4">Tokenisation is a method of converting the complete text into tokens, i.e. converting the sentences into individual words.</p><pre name="ab4d" id="ab4d" class="graf graf--pre graf-after--p">import nltk<br>nltk.download(&#39;punkt&#39;)<br>from nltk.tokenize import word_tokenize</pre><pre name="bde0" id="bde0" class="graf graf--pre graf-after--pre">text = &quot;What is NLP Why do we need to reduce noise&quot;<br>tokenized = word_tokenize(text)</pre><pre name="69d2" id="69d2" class="graf graf--pre graf-after--pre">print(tokenized)</pre><pre name="4e26" id="4e26" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">#[&#39;What&#39;, &#39;is&#39;, &#39;NLP&#39;, &#39;Why&#39;, &#39;do&#39;, &#39;we&#39;, &#39;need&#39;, &#39;to&#39;, &#39;reduce&#39;, &#39;noise&#39;]</em></pre><h4 name="9e0e" id="9e0e" class="graf graf--h4 graf-after--pre">Text Normalisation</h4><p name="4960" id="4960" class="graf graf--p graf-after--h4">Text normalization plays a major role in test data preprocessing. Usually, text data contains various types of similar words or the same words with different affixes. For eg: ‘jumps’, ‘jumping’, and ‘jumped’ are all the variations of the word ‘jump’. These words have the same meaning, and they are needed to be normalized to their base form. We have two popular methods to normalize data:</p><ul class="postList"><li name="ca4a" id="ca4a" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Stemming</strong></li><li name="cdc3" id="cdc3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Lemmatization</strong></li></ul><h4 name="d869" id="d869" class="graf graf--h4 graf-after--li">Stemming</h4><p name="d680" id="d680" class="graf graf--p graf-after--h4">Stemming is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word.</p><pre name="8ba6" id="8ba6" class="graf graf--pre graf-after--p">from nltk.stem import PorterStemmer</pre><pre name="668f" id="668f" class="graf graf--pre graf-after--pre">tokenized = [[&quot;So&quot;,&quot;kangaroos&quot;, &quot;many&quot;, &quot;jumped&quot;, &quot;jump&quot;, &quot;jumping&quot;]</pre><pre name="f9ec" id="f9ec" class="graf graf--pre graf-after--pre">stemmer = PorterStemmer()<br>stemmed = [stemmer.stem(token) for token in tokenized]</pre><pre name="d183" id="d183" class="graf graf--pre graf-after--pre">print(stemmed)</pre><pre name="0723" id="0723" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">#[&#39;I&#39;, &#39;kangaroo&#39;, &#39;mani&#39;, &#39;jump&#39;, &#39;jump&#39;, &#39;jump&#39;]</em></pre><p name="b1a3" id="b1a3" class="graf graf--p graf-after--pre">You can observe in the above output, but the problem is that the word ‘many’ is converted to ‘mani’ and that’s the limitation of stemming. This is reduced by lemmatization.</p><h4 name="7166" id="7166" class="graf graf--h4 graf-after--p">Lemmatization</h4><p name="5195" id="5195" class="graf graf--p graf-after--h4">Lemmatization is a step by step, organized procedure to obtain a root word. Lemmatization is preferred over Stemming because lemmatization does a <strong class="markup--strong markup--p-strong">morphological analysis</strong> of the words.</p><pre name="ece5" id="ece5" class="graf graf--pre graf-after--p">from nltk.stem import WordNetLemmatizer</pre><pre name="cc81" id="cc81" class="graf graf--pre graf-after--pre">tokenized = [&quot;So&quot;,&quot;kangaroos&quot;, &quot;many&quot;, &quot;jumped&quot;, &quot;jump&quot;, &quot;jumping&quot;]</pre><pre name="e071" id="e071" class="graf graf--pre graf-after--pre">lemmatizer = WordNetLemmatizer()<br>lemmatized = [lemmatizer.lemmatize(token) for token in tokenized]</pre><pre name="fe86" id="fe86" class="graf graf--pre graf-after--pre">print(lemmatized)</pre><pre name="ab37" id="ab37" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">#[&#39;So&#39;, &#39;kangaroo&#39;, &#39;many&#39;, &#39;jumped&#39;, &#39;jump&#39;, &#39;jumping&#39;]</em></pre><h4 name="4a9c" id="4a9c" class="graf graf--h4 graf-after--pre">Stopwords Removal</h4><p name="3090" id="3090" class="graf graf--p graf-after--h4">Words like ‘a’, ‘an’, and ‘the’ are commonly used in a document and these words don’t provide the essence or meaning of that doc. These words are filtered out from the doc before applying to the train. NLTK already comes with a list of predefined stopwords, making the code easy.</p><pre name="1e16" id="1e16" class="graf graf--pre graf-after--p">from nltk.corpus import stopwords</pre><pre name="dd04" id="dd04" class="graf graf--pre graf-after--pre">word_tokens = [&#39;I&#39;, &#39;am&#39;, &#39;a&#39;, &#39;very&#39;, &#39;good&#39;, &#39;programmer&#39;]<br># define set of English stopwords<br>stop_words = set(stopwords.words(&#39;english&#39;))</pre><pre name="19f1" id="19f1" class="graf graf--pre graf-after--pre"># remove stopwords from tokens in dataset<br>statement_no_stop = [word for word in word_tokens if word not in stop_words]</pre><pre name="fb18" id="fb18" class="graf graf--pre graf-after--pre">print(statement_no_stop)</pre><pre name="4690" id="4690" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">#[&#39;I&#39;, &#39;good&#39;, &#39;programmer&#39;]</em></pre><p name="ce46" id="ce46" class="graf graf--p graf-after--pre">Now that we have removed almost all the noise from the data, it’s time to analyze data by converting the tokens into features. We will discuss this in the next part.</p><p name="2a17" id="2a17" class="graf graf--p graf-after--p graf--trailing">Till then, Bye. See ya..!</p></div></div></section>
</section><!--
<footer><p>By <a href="https://medium.com/@deeppatel23" class="p-author h-card">Deep Patel</a> on <a href="https://medium.com/p/685a6e41fd3f"><time class="dt-published" datetime="2020-08-11T04:46:31.025Z">August 11, 2020</time></a>.</p><p><a href="https://medium.com/@deeppatel23/introduction-to-natural-language-processing-685a6e41fd3f" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on September 4, 2020.</p></footer>--></article></body></html>